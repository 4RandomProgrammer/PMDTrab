{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Test Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "DATA_PATH = './data'\n",
    "DATA_FILE = './data.zip'\n",
    "KUDU_MASTER = 'kudu-master-1:7051'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kudu Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = f'--packages org.apache.kudu:kudu-spark3_2.12:1.13.0.7.1.5.17-1,org.neo4j:neo4j-connector-apache-spark_2.12:5.0.1_for_spark_3 --repositories https://repository.cloudera.com/artifactory/cloudera-repos/ pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config('spark.packages', 'org.apache.kudu:kudu-spark3_2.12:1.13.0.7.1.5.17-1,org.neo4j:neo4j-connector-apache-spark_2.12:5.0.1_for_spark_3').getOrCreate()\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc.setLogLevel('OFF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4j Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial read from neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[<id>: bigint, <labels>: array<string>, name: string, id: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+---+\n",
      "|<id>|<labels>|name  |id |\n",
      "+----+--------+------+---+\n",
      "|0   |[Person]|John  |1  |\n",
      "|1   |[Person]|Thomas|2  |\n",
      "|2   |[Person]|Carlos|3  |\n",
      "|3   |[Person]|Jarles|4  |\n",
      "+----+--------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"org.neo4j.spark.DataSource\")\\\n",
    " .option(\"url\", \"bolt://neo4j:7687\")\\\n",
    " .option(\"authentication.type\", \"none\")\\\n",
    " .option(\"labels\", \"Person\")\\\n",
    " .load()\n",
    "display(df)\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing 2 nodes into neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    " [(3, \"Carlos\"),(4, \"Jarles\")],\n",
    " [\"id\", \"name\"]\n",
    ")\n",
    "df.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    " .option(\"url\", \"bolt://neo4j:7687\")\\\n",
    " .option(\"authentication.type\", \"none\")\\\n",
    " .option(\"labels\", \":Person\")\\\n",
    " .option(\"node.keys\", \"id\")\\\n",
    " .mode(\"Overwrite\")\\\n",
    " .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading neo4j again, should return the new nodes inserted in the above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[<id>: bigint, <labels>: array<string>, name: string, id: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+---+\n",
      "|<id>|<labels>|name  |id |\n",
      "+----+--------+------+---+\n",
      "|0   |[Person]|John  |1  |\n",
      "|1   |[Person]|Thomas|2  |\n",
      "|2   |[Person]|Carlos|3  |\n",
      "|3   |[Person]|Jarles|4  |\n",
      "+----+--------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"org.neo4j.spark.DataSource\")\\\n",
    " .option(\"url\", \"bolt://neo4j:7687\")\\\n",
    " .option(\"authentication.type\", \"none\")\\\n",
    " .option(\"labels\", \"Person\")\\\n",
    " .load()\n",
    "display(df)\n",
    "df.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
