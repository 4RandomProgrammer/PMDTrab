{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Test Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "DATA_PATH = './data'\n",
    "DATA_FILE = './data.zip'\n",
    "KUDU_MASTER = 'kudu-master-1:7051'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kudu Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = f'--packages org.apache.kudu:kudu-spark3_2.12:1.13.0.7.1.5.17-1,org.neo4j:neo4j-connector-apache-spark_2.12:5.0.1_for_spark_3 --repositories https://repository.cloudera.com/artifactory/cloudera-repos/ pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config('spark.packages', 'org.apache.kudu:kudu-spark3_2.12:1.13.0.7.1.5.17-1,org.neo4j:neo4j-connector-apache-spark_2.12:5.0.1_for_spark_3').getOrCreate()\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc.setLogLevel('OFF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[literal: string, nota: decimal(8,5), dados: decimal(8,5), idade: int, lorem: int, ipsum: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+-----+-----+-----+\n",
      "|literal|nota|dados|idade|lorem|ipsum|\n",
      "+-------+----+-----+-----+-----+-----+\n",
      "+-------+----+-----+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = spark.read.option('kudu.master', KUDU_MASTER).option('kudu.table', f'impala::default.testA').format('kudu').load()\n",
    "table.createOrReplaceTempView('testA')\n",
    "display(table)\n",
    "table.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kudu = spark.createDataFrame(\n",
    " [(\"conseguimos?\", 3.2, 2.0, 1000, 300, \"sad\"),(\"teste\", 22.5,4.75, -500, -1000, \"Jarles\")],\n",
    " [\"literal\",\"nota\", \"dados\",\"idade\",\"lorem\",\"ipsum\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kudu = df_kudu.withColumn('nota', df_kudu.nota.cast(DecimalType(8, 5))) \\\n",
    "    .withColumn('dados', df_kudu.dados.cast(DecimalType(8, 5))) \\\n",
    "    .withColumn('idade', df_kudu.idade.cast(IntegerType())) \\\n",
    "    .withColumn('lorem', df_kudu.lorem.cast(IntegerType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kudu.write.option('kudu.master', KUDU_MASTER).option('kudu.table', f'impala::default.testA').mode('append').format('kudu').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[literal: string, nota: decimal(8,5), dados: decimal(8,5), idade: int, lorem: int, ipsum: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-------+-----+-----+------+\n",
      "|literal     |nota    |dados  |idade|lorem|ipsum |\n",
      "+------------+--------+-------+-----+-----+------+\n",
      "|conseguimos?|3.20000 |2.00000|1000 |300  |sad   |\n",
      "|teste       |22.50000|4.75000|-500 |-1000|Jarles|\n",
      "+------------+--------+-------+-----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table = spark.read.option('kudu.master', KUDU_MASTER).option('kudu.table', f'impala::default.testA').format('kudu').load()\n",
    "table.createOrReplaceTempView('testA')\n",
    "display(table)\n",
    "table.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4j Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial read from neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[<id>: bigint, <labels>: array<string>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|<id>|<labels>|\n",
      "+----+--------+\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"org.neo4j.spark.DataSource\")\\\n",
    " .option(\"url\", \"bolt://neo4j:7687\")\\\n",
    " .option(\"authentication.type\", \"none\")\\\n",
    " .option(\"labels\", \"Person\")\\\n",
    " .load()\n",
    "display(df)\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing 2 nodes into neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    " [(3, \"Carlos\"),(4, \"Jarles\")],\n",
    " [\"id\", \"name\"]\n",
    ")\n",
    "df.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    " .option(\"url\", \"bolt://neo4j:7687\")\\\n",
    " .option(\"authentication.type\", \"none\")\\\n",
    " .option(\"labels\", \":Person\")\\\n",
    " .option(\"node.keys\", \"id\")\\\n",
    " .mode(\"Overwrite\")\\\n",
    " .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading neo4j again, should return the new nodes inserted in the above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[<id>: bigint, <labels>: array<string>, name: string, id: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+---+\n",
      "|<id>|<labels>|name  |id |\n",
      "+----+--------+------+---+\n",
      "|0   |[Person]|Carlos|3  |\n",
      "|1   |[Person]|Jarles|4  |\n",
      "+----+--------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"org.neo4j.spark.DataSource\")\\\n",
    " .option(\"url\", \"bolt://neo4j:7687\")\\\n",
    " .option(\"authentication.type\", \"none\")\\\n",
    " .option(\"labels\", \"Person\")\\\n",
    " .load()\n",
    "display(df)\n",
    "df.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
